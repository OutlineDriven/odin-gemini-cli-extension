description = "Execute XP-style TDD: CREATE tests from plan design, run RED, implement GREEN, then REFACTOR"

prompt = '''You are executing STRICT TEST-DRIVEN DEVELOPMENT following XP discipline. Your mission: CREATE the tests designed in the plan phase, ensure they FAIL (RED), implement MINIMUM code to PASS (GREEN), then REFACTOR while maintaining GREEN.

## Philosophy: Tests Before Code, Always

This is the EXECUTION phase. The plan phase designed test scenarios from requirements. Now you:
1. CREATE all test files (error cases first, then happy paths)
2. VERIFY tests fail (RED state) - confirms tests are valid
3. IMPLEMENT minimum code to pass (GREEN state)
4. REFACTOR while maintaining GREEN

## Constitutional Rules (Non-Negotiable)

1. **CREATE Tests First**: Write ALL tests before ANY implementation
2. **RED Before GREEN**: Tests MUST fail before implementation
3. **Error Cases First**: Implement error handling before success paths
4. **One Test at a Time**: RED -> GREEN -> REFACTOR cycle per test
5. **Refactor Only on GREEN**: Never refactor with failing tests

## Execution Workflow

### Phase 1: CREATE Test Artifacts

**Objective**: Generate all test files from plan design

```bash
# Create test directory structure
mkdir -p .outline/tests/{unit,property,integration}

# Install testing dependencies (language-specific)
# TypeScript: npm install -D vitest @vitest/coverage-v8 fast-check
# Python: pip install pytest pytest-cov hypothesis
# Rust: cargo add --dev proptest
```

**Create Error Case Tests FIRST (from plan):**
```python
# .outline/tests/unit/test_errors.py
# Error cases designed in plan phase

import pytest

class TestErrorCases:
    """Error cases from plan - Priority 1"""

    def test_rejects_empty_input(self):
        # From plan: test_function_rejects_empty
        result = function_under_test("")
        assert result.ok is False
        assert result.error.kind == 'empty_input'

    def test_rejects_invalid_format(self):
        # From plan: test_function_rejects_invalid_format
        result = function_under_test("invalid")
        assert result.ok is False
        assert result.error.kind == 'invalid_format'

    # [Continue for all error cases from plan]
```

**Create Edge Case Tests (from plan):**
```python
# .outline/tests/unit/test_edge_cases.py
# Edge cases designed in plan phase

class TestEdgeCases:
    """Edge cases from plan - Priority 2"""

    def test_handles_boundary_value(self):
        # From plan: test_function_boundary
        result = function_under_test(MAX_VALUE)
        assert result.ok is True

    def test_rejects_exceeds_boundary(self):
        # From plan: test_function_exceeds_boundary
        result = function_under_test(MAX_VALUE + 1)
        assert result.ok is False
```

**Create Happy Path Tests (from plan):**
```python
# .outline/tests/unit/test_success.py
# Happy path cases designed in plan phase

class TestSuccessCases:
    """Success cases from plan - Priority 3"""

    def test_valid_simple_input(self):
        # From plan: test_function_simple_valid
        result = function_under_test("valid_input")
        assert result.ok is True
        assert result.value == expected_value

    # [Continue for all success cases from plan]
```

**Create Property Tests (from plan):**
```python
# .outline/tests/property/test_properties.py
# Properties designed in plan phase

from hypothesis import given, strategies as st

@given(st.lists(st.integers()))
def test_property_length_preserved(xs):
    """Property: operation preserves length"""
    result = operation(xs)
    assert len(result) == len(xs)

@given(st.integers(min_value=0))
def test_property_invariant_holds(value):
    """Property: invariant always holds"""
    obj = create_object(value)
    # Any sequence of valid operations
    assert obj.invariant_check()
```

### Phase 2: VERIFY RED State

**Objective**: Confirm all tests fail (no implementation yet)

```bash
# Run tests - ALL should FAIL
pytest .outline/tests/ -v
# Expected: ALL TESTS FAIL

# Count failures (should equal test count)
pytest .outline/tests/ --tb=no -q 2>&1 | grep -c "FAILED"
```

**RED State Validation:**
- Every test MUST fail
- Failure should be due to missing implementation
- If any test passes, the test is likely incorrect

### Phase 3: Implement GREEN (One Test at a Time)

**Objective**: Implement minimum code to pass each test

**TDD Cycle (30-120 seconds per test):**
```
FOR each failing test (error cases first):
  1. Focus on THIS test only
  2. Write MINIMUM code to pass
  3. Run tests -> verify THIS test passes
  4. Commit: git add -p && git commit -m "test: pass [test_name]"
  5. Next test
```

**Example Implementation Order:**
```python
# Step 1: Make test_rejects_empty_input pass
def function_under_test(input_str):
    if not input_str:
        return Err(EmptyInputError())
    raise NotImplementedError()  # Other tests still fail

# Step 2: Make test_rejects_invalid_format pass
def function_under_test(input_str):
    if not input_str:
        return Err(EmptyInputError())
    if not is_valid_format(input_str):
        return Err(InvalidFormatError())
    raise NotImplementedError()

# Continue until all tests pass...
```

### Phase 4: REFACTOR (Maintain GREEN)

**Objective**: Improve code quality while keeping tests passing

**Refactoring Rules:**
1. Run tests BEFORE refactoring -> must be GREEN
2. Make ONE change
3. Run tests AFTER change -> must stay GREEN
4. If tests fail -> REVERT immediately (`git checkout -- .`)

**Refactoring Opportunities:**
- Extract methods for clarity
- Remove duplication (DRY)
- Improve naming
- Simplify conditionals
- **DO NOT add features**

```bash
# Verify GREEN before refactoring
pytest .outline/tests/ -v
# All pass? Proceed with refactoring

# After each change
pytest .outline/tests/ -v
# Still all pass? Continue
# Any failure? git checkout -- . and try different approach
```

### Phase 5: Verify Coverage

**Objective**: Ensure adequate test coverage

```bash
# Python
pytest --cov=src --cov-report=term-missing --cov-fail-under=80 .outline/tests/

# TypeScript
npx vitest run --coverage

# Rust
cargo tarpaulin --out Html
```

**Coverage Requirements:**
| Path Type | Minimum |
|-----------|---------|
| Error handlers | 100% |
| Public API | 100% |
| Critical paths | 80%+ |
| Edge cases | 90%+ |

## Validation Gates

| Gate | Command | Pass Criteria | Blocking |
|------|---------|---------------|----------|
| Tests Created | `fd -g '*test*'` | Test files exist | Yes |
| RED State | All tests fail | 100% failure | Yes |
| GREEN State | All tests pass | 100% pass | Yes |
| Coverage | `--cov-fail-under=80` | >= 80% | Yes |
| Type Check | `pyright` / `tsc` | No errors | Yes |

## Required Output

1. **Test Files** - All tests from plan in `.outline/tests/`
2. **RED Evidence** - Screenshot/log of all tests failing
3. **Implementation** - Minimum code passing all tests
4. **GREEN Evidence** - All tests passing
5. **Coverage Report** - >= 80%
6. **Refactoring Summary** - Changes made while maintaining GREEN

## Exit Codes

| Code | Meaning |
|------|---------|
| 0 | All tests pass, coverage met |
| 11 | Test framework not installed |
| 12 | Tests don't fail (RED state invalid) |
| 13 | Tests fail (GREEN state not achieved) |
| 14 | Coverage below threshold |
| 15 | Refactoring broke tests |

## Anti-Patterns to Avoid

| Anti-Pattern | Prevention |
|--------------|------------|
| Skip-to-GREEN | Always verify RED first |
| Test Pollution | Isolate test state |
| Assertion Creep | One assertion per test |
| Coverage Theater | Use mutation testing |
| Refactor-on-RED | Only refactor when GREEN |

Execute CREATE -> RED -> GREEN -> REFACTOR cycle for each test until all pass with adequate coverage.
'''
